(self.webpackChunkweave_gitops_docs=self.webpackChunkweave_gitops_docs||[]).push([[7895],{91262:function(e,t,n){"use strict";var a=n(67294),o=n(52263);t.Z=function(e){var t=e.children,n=e.fallback;return(0,o.Z)().isClient&&null!=t?a.createElement(a.Fragment,null,t()):n||null}},40642:function(e,t,n){"use strict";n.d(t,{Z:function(){return r}});var a=n(67294),o=n(36742),i=n(28084),s={fontSize:16,marginLeft:4,fontVariant:"all-small-caps"};function r(e){var t,n,r,l,c=e.tiers;return a.createElement(o.Z,{to:(r=(0,i.default)()["docusaurus-plugin-content-docs"],l=null==r||null==(t=r.default)||null==(n=t.versions)?void 0:n.find((function(e){return"current"===e.name})),((null==l?void 0:l.path)||"/docs")+"/enterprise/intro"),title:"This feature is a available on "+c,style:s},c)}},47814:function(e,t,n){"use strict";n.r(t),n.d(t,{contentTitle:function(){return u},default:function(){return f},frontMatter:function(){return p},metadata:function(){return d},toc:function(){return m}});var a=n(22122),o=n(19756),i=(n(67294),n(3905)),s=n(40642),r=n(11756),l=n(91262),c=n(38378),p={title:"Getting started",sidebar_position:1,hide_title:!0},u=void 0,d={unversionedId:"cluster-management/getting-started",id:"version-0.5.0/cluster-management/getting-started",isDocsHomePage:!1,title:"Getting started",description:"{frontMatter.title}",source:"@site/versioned_docs/version-0.5.0/cluster-management/getting-started.mdx",sourceDirName:"cluster-management",slug:"/cluster-management/getting-started",permalink:"/docs/cluster-management/getting-started",editUrl:"https://github.com/weaveworks/weave-gitops-docs/edit/main/versioned_docs/version-0.5.0/cluster-management/getting-started.mdx",version:"0.5.0",sidebarPosition:1,frontMatter:{title:"Getting started",sidebar_position:1,hide_title:!0},sidebar:"version-0.5.0/tutorialSidebar",previous:{title:"Introduction",permalink:"/docs/cluster-management/intro"},next:{title:"Managing existing clusters",permalink:"/docs/cluster-management/managing-existing-clusters"}},m=[{value:"Creating your first CAPD Cluster",id:"creating-your-first-capd-cluster",children:[{value:"1. Configure a capi provider",id:"1-configure-a-capi-provider",children:[]},{value:"2. Add a template",id:"2-add-a-template",children:[]}]},{value:"Automatically install a CNI with <code>ClusterResourceSet</code>s",id:"automatically-install-a-cni-with-clusterresourcesets",children:[{value:"1. Add a CRS to install a CNI",id:"1-add-a-crs-to-install-a-cni",children:[]}]},{value:"Profiles and clusters",id:"profiles-and-clusters",children:[]},{value:"Test",id:"test",children:[]}],g={toc:m};function f(e){var t=e.components,u=(0,o.Z)(e,["components"]);return(0,i.kt)("wrapper",(0,a.Z)({},g,u,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",null,p.title," ",(0,i.kt)(s.Z,{tiers:"enterprise",mdxType:"TierLabel"})),(0,i.kt)("h2",{id:"creating-your-first-capd-cluster"},"Creating your first CAPD Cluster"),(0,i.kt)("p",null,"If you've followed the ",(0,i.kt)("a",{parentName:"p",href:"/docs/enterprise/upgrading"},"Upgrade guide")," you should have a management cluster ready to roll. Next up we'll"),(0,i.kt)("h3",{id:"1-configure-a-capi-provider"},"1. Configure a capi provider"),(0,i.kt)("p",null,"If you have not already done so, install and configure at least one CAPI provider."),(0,i.kt)("p",null,"See ",(0,i.kt)("a",{parentName:"p",href:"/docs/cluster-management/cluster-api-providers"},"Cluster API Providers")," page for more details on providers. He're we'll continue with ",(0,i.kt)("inlineCode",{parentName:"p"},"kind")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"capd")," as an example."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# Enable support for `ClusterResourceSet`s for automatically installing CNIs\nexport EXP_CLUSTER_RESOURCE_SET=true\nclusterctl init --infrastructure docker\n")),(0,i.kt)("h3",{id:"2-add-a-template"},"2. Add a template"),(0,i.kt)("p",null,"See ",(0,i.kt)("a",{parentName:"p",href:"/docs/cluster-management/templates"},"CAPI Templates")," page for more details on this topic. Once we load a template we can use it in the UI to create clusters!"),(0,i.kt)("p",null,"Download the template below to your config repository path, then commit and push to your git origin."),(0,i.kt)(l.Z,{mdxType:"BrowserOnly"},(function(){return(0,i.kt)(r.Z,{className:"language-bash",mdxType:"CodeBlock"},"curl -o .weave-gitops/apps/capi/templates/capd-template.yaml"," ",window.location.protocol,"//",window.location.host,n(71).Z)})),(0,i.kt)(r.Z,{title:".weave-gitops/apps/capi/templates/capd-template.yaml",className:"language-yaml",mdxType:"CodeBlock"},c.Z),(0,i.kt)("h2",{id:"automatically-install-a-cni-with-clusterresourcesets"},"Automatically install a CNI with ",(0,i.kt)("inlineCode",{parentName:"h2"},"ClusterResourceSet"),"s"),(0,i.kt)("p",null,"We can use ",(0,i.kt)("inlineCode",{parentName:"p"},"ClusterResourceSet"),"s to automatically install CNI's on a new cluster, here we use calico as an example."),(0,i.kt)("h3",{id:"1-add-a-crs-to-install-a-cni"},"1. Add a CRS to install a CNI"),(0,i.kt)("p",null,"Create a calico configmap and a CRS as follows:"),(0,i.kt)(l.Z,{mdxType:"BrowserOnly"},(function(){return(0,i.kt)(r.Z,{className:"language-bash",mdxType:"CodeBlock"},"mkdir -p .weave-gitops/apps/capi/bootstrap","\n","curl -o .weave-gitops/apps/capi/bootstrap/calico-crs.yaml ",window.location.protocol,"//",window.location.host,n(86579).Z,"\n","curl -o .weave-gitops/apps/capi/bootstrap/calico-crs-configmap.yaml"," ",window.location.protocol,"//",window.location.host,n(16524).Z)})),(0,i.kt)(r.Z,{title:".weave-gitops/apps/capi/boostrap/calico-crs.yaml",className:"language-yaml",mdxType:"CodeBlock"},"apiVersion: addons.cluster.x-k8s.io/v1alpha3\nkind: ClusterResourceSet\nmetadata:\n  name: calico-crs\n  namespace: default\nspec:\n  clusterSelector:\n    matchLabels:\n      cni: calico\n  resources:\n  - kind: ConfigMap\n    name: calico-crs-configmap\n\n"),(0,i.kt)("p",null,"The full ",(0,i.kt)("a",{target:"_blank",href:n(19824).Z},(0,i.kt)("code",null,"calico-crs-configmap.yaml"))," is a bit large to display inline here but make sure to download it to ",(0,i.kt)("inlineCode",{parentName:"p"},".weave-gitops/apps/capi/bootstrap/calico-crs-configmap.yaml")," too, manually or with the above ",(0,i.kt)("inlineCode",{parentName:"p"},"curl")," command."),(0,i.kt)("h2",{id:"profiles-and-clusters"},"Profiles and clusters"),(0,i.kt)("p",null,"WGE can automatically install profiles onto new clusters"),(0,i.kt)("h4",{id:"1-add-a-helmrepo"},"1. Add a helmrepo"),(0,i.kt)("p",null,"A profile is an enhanced helm chart. When publishing profiles to helm repositories make sure to include the ",(0,i.kt)("inlineCode",{parentName:"p"},"weave.works/profile")," in ",(0,i.kt)("inlineCode",{parentName:"p"},"Chart.yaml"),". These annotated profiles will appear in WGE"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"annotations:\n  weave.works/profile: nginx-profile\n")),(0,i.kt)("p",null,"Download the profile repositry below to your config repository path then commit and push. Make sure to update the url to point to a helm repository containing your profiles."),(0,i.kt)(l.Z,{mdxType:"BrowserOnly"},(function(){return(0,i.kt)(r.Z,{className:"language-bash",mdxType:"CodeBlock"},"mkdir -p .weave-gitops/apps/capi/profiles","\n","curl -o .weave-gitops/apps/capi/profiles/profile-repo.yaml ",window.location.protocol,"//",window.location.host,n(35085).Z)})),(0,i.kt)(r.Z,{title:".weave-gitops/apps/capi/profiles/profile-repo.yaml",className:"language-yaml",mdxType:"CodeBlock"},"apiVersion: source.toolkit.fluxcd.io/v1beta1\nkind: HelmRepository\nmetadata:\n  creationTimestamp: null\n  name: weaveworks-charts\n  namespace: wego-system\nspec:\n  interval: 1m\n  url: https://my-org.github.io/profiles\nstatus: {}\n"),(0,i.kt)("h4",{id:"3-add-a-cluster-bootstrap-config"},"3. Add a cluster bootstrap config"),(0,i.kt)("p",null,"Create a cluster bootstrap config as follows:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"}," kubectl create secret generic my-pat --from-literal GITHUB_TOKEN=$GITHUB_TOKEN\n")),(0,i.kt)("p",null,"Download the config with"),(0,i.kt)(l.Z,{mdxType:"BrowserOnly"},(function(){return(0,i.kt)(r.Z,{className:"language-bash",mdxType:"CodeBlock"},"mkdir -p .weave-gitops/apps/capi/bootstrap","\n","curl -o .weave-gitops/apps/capi/bootstrap/capi-gitops-cluster-bootstrap-config.yaml"," ",window.location.protocol,"//",window.location.host,n(17054).Z)})),(0,i.kt)("p",null,"Then update the ",(0,i.kt)("inlineCode",{parentName:"p"},"GITOPS_REPO")," variable to point to your cluster"),(0,i.kt)(r.Z,{title:".weave-gitops/apps/capi/boostrap/capi-gitops-cluster-bootstrap-config.yaml",className:"language-yaml",mdxType:"CodeBlock"},'apiVersion: capi.weave.works/v1alpha1\nkind: ClusterBootstrapConfig\nmetadata:\n  name: capi-gitops\n  namespace: default\nspec:\n  clusterSelector:\n    matchLabels:\n      weave.works/capi: bootstrap\n  jobTemplate:\n    generateName: "run-gitops-{{ .ObjectMeta.Name }}"\n    spec:\n      containers:\n        - image: ghcr.io/palemtnrider/wego-app:v0.5.0-rc2\n          name: gitops-install\n          resources: {}\n          volumeMounts:\n            - name: kubeconfig\n              mountPath: "/etc/gitops"\n              readOnly: true\n          args:\n            [\n              "install",\n              "--override-in-cluster",\n              "--app-config-url",\n              "$(GITOPS_REPO)",\n            ]\n          env:\n            - name: KUBECONFIG\n              value: "/etc/gitops/value"\n            - name: GITOPS_REPO\n              value: "ssh://git@github.com/my-org/my-management-cluster.git"\n            - name: GITHUB_TOKEN\n              valueFrom:\n                secretKeyRef:\n                  name: my-pat\n                  key: GITHUB_TOKEN\n          # - name: GITLAB_TOKEN # If your GitOps reop is on GitLab, use this instead of GITHUB_TOKEN\n          #   valueFrom:\n          #     secretKeyRef:\n          #       name: pat\n          #       key: GITLAB_TOKEN\n      restartPolicy: Never\n      volumes:\n        - name: kubeconfig\n          secret:\n            secretName: "{{ .ObjectMeta.Name }}-kubeconfig"\n'),(0,i.kt)("h2",{id:"test"},"Test"),(0,i.kt)("p",null,"You should now be able to create a new cluster from your template and install profiles onto it with a single Pull Request via the WGE UI!"))}f.isMDXComponent=!0},16524:function(e,t,n){"use strict";t.Z=n.p+"assets/files/calico-crs-configmap-c9a5eb78b26c51e350118feaf4fdeeac.yaml"},86579:function(e,t,n){"use strict";t.Z=n.p+"assets/files/calico-crs-cf0fc463720dc26518b2a4758781bbc5.yaml"},17054:function(e,t,n){"use strict";t.Z=n.p+"assets/files/capi-gitops-cluster-bootstrap-config-e1e68a69486744909741b39a355833d6.yaml"},35085:function(e,t,n){"use strict";t.Z=n.p+"assets/files/profile-repo-69ff459a42f2a570d6ffba18de440b16.yaml"},71:function(e,t,n){"use strict";t.Z=n.p+"assets/files/capd-template-c2067f81c076807ba4747da230440d4c.yaml"},19824:function(e,t,n){"use strict";t.Z=n.p+"assets/files/calico-crs-configmap-c9a5eb78b26c51e350118feaf4fdeeac.yaml"},38378:function(e,t){"use strict";t.Z='apiVersion: capi.weave.works/v1alpha1\nkind: CAPITemplate\nmetadata:\n  name: cluster-template-development\n  namespace: default\nspec:\n  description: This is the std. CAPD template\n  params:\n    - name: CLUSTER_NAME\n      description: This is used for the cluster naming.\n    - name: NAMESPACE\n      description: Namespace to create the cluster in.\n    - name: KUBERNETES_VERSION\n      description: The version of Kubernetes to use.\n      options: ["1.19.11", "1.20.7", "1.21.1"]\n  resourcetemplates:\n    - apiVersion: cluster.x-k8s.io/v1beta1\n      kind: Cluster\n      metadata:\n        name: "${CLUSTER_NAME}"\n        namespace: "${NAMESPACE}"\n        labels:\n          cni: calico\n          weave.works/capi: bootstrap\n      spec:\n        clusterNetwork:\n          services:\n            cidrBlocks:\n              - 10.128.0.0/12\n          pods:\n            cidrBlocks:\n              - 192.168.0.0/16\n          serviceDomain: cluster.local\n        infrastructureRef:\n          apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n          kind: DockerCluster\n          name: "${CLUSTER_NAME}"\n          namespace: "${NAMESPACE}"\n        controlPlaneRef:\n          kind: KubeadmControlPlane\n          apiVersion: controlplane.cluster.x-k8s.io/v1beta1\n          name: "${CLUSTER_NAME}-control-plane"\n          namespace: "${NAMESPACE}"\n    - apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n      kind: DockerCluster\n      metadata:\n        name: "${CLUSTER_NAME}"\n        namespace: "${NAMESPACE}"\n    - apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n      kind: DockerMachineTemplate\n      metadata:\n        name: "${CLUSTER_NAME}-control-plane"\n        namespace: "${NAMESPACE}"\n      spec:\n        template:\n          spec:\n            extraMounts:\n              - containerPath: "/var/run/docker.sock"\n                hostPath: "/var/run/docker.sock"\n    - kind: KubeadmControlPlane\n      apiVersion: controlplane.cluster.x-k8s.io/v1beta1\n      metadata:\n        name: "${CLUSTER_NAME}-control-plane"\n        namespace: "${NAMESPACE}"\n      spec:\n        replicas: 1\n        machineTemplate:\n          infrastructureRef:\n            kind: DockerMachineTemplate\n            apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n            name: "${CLUSTER_NAME}-control-plane"\n            namespace: "${NAMESPACE}"\n        kubeadmConfigSpec:\n          clusterConfiguration:\n            controllerManager:\n              extraArgs: { enable-hostpath-provisioner: "true" }\n            apiServer:\n              certSANs: [localhost, 127.0.0.1]\n          initConfiguration:\n            nodeRegistration:\n              criSocket: /var/run/containerd/containerd.sock\n              kubeletExtraArgs:\n                # We have to pin the cgroupDriver to cgroupfs as kubeadm >=1.21 defaults to systemd\n                # kind will implement systemd support in: https://github.com/kubernetes-sigs/kind/issues/1726\n                cgroup-driver: cgroupfs\n                eviction-hard: "nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%"\n          joinConfiguration:\n            nodeRegistration:\n              criSocket: /var/run/containerd/containerd.sock\n              kubeletExtraArgs:\n                # We have to pin the cgroupDriver to cgroupfs as kubeadm >=1.21 defaults to systemd\n                # kind will implement systemd support in: https://github.com/kubernetes-sigs/kind/issues/1726\n                cgroup-driver: cgroupfs\n                eviction-hard: "nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%"\n        version: "${KUBERNETES_VERSION}"\n    - apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n      kind: DockerMachineTemplate\n      metadata:\n        name: "${CLUSTER_NAME}-md-0"\n        namespace: "${NAMESPACE}"\n      spec:\n        template:\n          spec: {}\n    - apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n      kind: KubeadmConfigTemplate\n      metadata:\n        name: "${CLUSTER_NAME}-md-0"\n        namespace: "${NAMESPACE}"\n      spec:\n        template:\n          spec:\n            joinConfiguration:\n              nodeRegistration:\n                kubeletExtraArgs:\n                  # We have to pin the cgroupDriver to cgroupfs as kubeadm >=1.21 defaults to systemd\n                  # kind will implement systemd support in: https://github.com/kubernetes-sigs/kind/issues/1726\n                  cgroup-driver: cgroupfs\n                  eviction-hard: "nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%"\n    - apiVersion: cluster.x-k8s.io/v1beta1\n      kind: MachineDeployment\n      metadata:\n        name: "${CLUSTER_NAME}-md-0"\n        namespace: "${NAMESPACE}"\n      spec:\n        clusterName: "${CLUSTER_NAME}"\n        replicas: 1\n        selector:\n          matchLabels:\n        template:\n          spec:\n            clusterName: "${CLUSTER_NAME}"\n            version: "${KUBERNETES_VERSION}"\n            bootstrap:\n              configRef:\n                name: "${CLUSTER_NAME}-md-0"\n                namespace: "${NAMESPACE}"\n                apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n                kind: KubeadmConfigTemplate\n            infrastructureRef:\n              name: "${CLUSTER_NAME}-md-0"\n              namespace: "${NAMESPACE}"\n              apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n              kind: DockerMachineTemplate\n'}}]);